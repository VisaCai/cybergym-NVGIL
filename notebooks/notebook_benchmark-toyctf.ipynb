{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-trash",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:33.757774Z",
     "iopub.status.busy": "2021-09-06T20:24:33.757163Z",
     "iopub.status.idle": "2021-09-06T20:24:33.761060Z",
     "shell.execute_reply": "2021-09-06T20:24:33.760360Z"
    },
    "papermill": {
     "duration": 0.023708,
     "end_time": "2021-09-06T20:24:33.761201",
     "exception": false,
     "start_time": "2021-09-06T20:24:33.737493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "\"\"\"Benchmark all the baseline agents\n",
    "on a given CyberBattleSim environment and compare\n",
    "them to the dumb 'random agent' baseline.\n",
    "\n",
    "NOTE: You can run this `.py`-notebook directly from VSCode.\n",
    "You can also generate a traditional Jupyter Notebook\n",
    "using the VSCode command `Export Currenty Python File As Jupyter Notebook`.\n",
    "\"\"\"\n",
    "\n",
    "# pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-legend",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:33.786186Z",
     "iopub.status.busy": "2021-09-06T20:24:33.785588Z",
     "iopub.status.idle": "2021-09-06T20:24:34.999817Z",
     "shell.execute_reply": "2021-09-06T20:24:35.000324Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 1.228952,
     "end_time": "2021-09-06T20:24:35.000504",
     "exception": false,
     "start_time": "2021-09-06T20:24:33.771552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kalic/Desktop/AI_P/CyberBattleSim\")\n",
    "import logging\n",
    "import gym\n",
    "import cyberbattle.agents.baseline.learner as learner\n",
    "import cyberbattle.agents.baseline.plotting as p\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "import cyberbattle.agents.baseline.agent_randomcredlookup as rca\n",
    "import cyberbattle.agents.baseline.agent_tabularqlearning as tqa\n",
    "import cyberbattle.agents.baseline.agent_dql as dqla\n",
    "from cyberbattle.agents.baseline.agent_wrapper import Verbosity\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR, format=\"%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0759501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-fairy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:35.025876Z",
     "iopub.status.busy": "2021-09-06T20:24:35.025247Z",
     "iopub.status.idle": "2021-09-06T20:24:35.027953Z",
     "shell.execute_reply": "2021-09-06T20:24:35.027322Z"
    },
    "papermill": {
     "duration": 0.016929,
     "end_time": "2021-09-06T20:24:35.028075",
     "exception": false,
     "start_time": "2021-09-06T20:24:35.011146",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill notebook parameters\n",
    "\n",
    "#############\n",
    "# gymid = 'CyberBattleTiny-v0'\n",
    "#############\n",
    "gymid = \"CyberBattleToyCtf-v0\"\n",
    "env_size = None\n",
    "iteration_count = 1500\n",
    "training_episode_count = 20\n",
    "eval_episode_count = 10\n",
    "maximum_node_count = 12\n",
    "maximum_total_credentials = 10\n",
    "#############\n",
    "# gymid = \"CyberBattleChain-v0\"\n",
    "# env_size = 10\n",
    "# iteration_count = 9000\n",
    "# training_episode_count = 50\n",
    "# eval_episode_count = 5\n",
    "# maximum_node_count = 22\n",
    "# maximum_total_credentials = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "paperback-specialist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:35.053626Z",
     "iopub.status.busy": "2021-09-06T20:24:35.053053Z",
     "iopub.status.idle": "2021-09-06T20:24:35.095265Z",
     "shell.execute_reply": "2021-09-06T20:24:35.095754Z"
    },
    "papermill": {
     "duration": 0.056673,
     "end_time": "2021-09-06T20:24:35.095931",
     "exception": false,
     "start_time": "2021-09-06T20:24:35.039258",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gymid = \"CyberBattleToyCtf-v0\"\n",
    "iteration_count = 1500\n",
    "training_episode_count = 20\n",
    "eval_episode_count = 10\n",
    "maximum_node_count = 12\n",
    "maximum_total_credentials = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preliminary-labor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:35.122824Z",
     "iopub.status.busy": "2021-09-06T20:24:35.122231Z",
     "iopub.status.idle": "2021-09-06T20:24:35.161944Z",
     "shell.execute_reply": "2021-09-06T20:24:35.162456Z"
    },
    "papermill": {
     "duration": 0.05715,
     "end_time": "2021-09-06T20:24:35.162615",
     "exception": false,
     "start_time": "2021-09-06T20:24:35.105465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Gym environment\n",
    "if env_size:\n",
    "    gym_env = gym.make(gymid, size=env_size)\n",
    "else:\n",
    "    gym_env = gym.make(gymid)\n",
    "\n",
    "ep = w.EnvironmentBounds.of_identifiers(\n",
    "    maximum_node_count=maximum_node_count,\n",
    "    maximum_total_credentials=maximum_total_credentials,\n",
    "    identifiers=gym_env.identifiers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-sheriff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:35.187163Z",
     "iopub.status.busy": "2021-09-06T20:24:35.186581Z",
     "iopub.status.idle": "2021-09-06T20:24:35.237429Z",
     "shell.execute_reply": "2021-09-06T20:24:35.236835Z"
    },
    "papermill": {
     "duration": 0.065022,
     "end_time": "2021-09-06T20:24:35.237561",
     "exception": false,
     "start_time": "2021-09-06T20:24:35.172539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debugging = False\n",
    "if debugging:\n",
    "    print(f\"port_count = {ep.port_count}, property_count = {ep.property_count}\")\n",
    "\n",
    "    gym_env.environment\n",
    "    # training_env.environment.plot_environment_graph()\n",
    "    gym_env.environment.network.nodes\n",
    "    gym_env.action_space\n",
    "    gym_env.action_space.sample()\n",
    "    gym_env.observation_space.sample()\n",
    "    o0 = gym_env.reset()\n",
    "    o_test, r, d, i = gym_env.step(gym_env.sample_valid_action())\n",
    "    o0 = gym_env.reset()\n",
    "\n",
    "    o0.keys()\n",
    "\n",
    "    fe_example = w.RavelEncoding(ep, [w.Feature_active_node_properties(ep), w.Feature_discovered_node_count(ep)])\n",
    "    a = w.StateAugmentation(o0)\n",
    "    w.Feature_discovered_ports(ep).get(a, None)\n",
    "    fe_example.encode_at(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8caf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toy_my_dql_run_round_5.pkl','rb') as file:\n",
    "    toy_my_dql_run_round_5 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c27535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### DQL\n",
      "Learning with: episode_count=20,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalic/Desktop/AI_P/CyberBattleSim/cyberbattle/agents/baseline/agent_dql.py:382: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  state_batch = torch.tensor(states_to_consider).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "  Episode 11 stopped at t=1500 \n",
      "  Episode 12 stopped at t=1500 \n",
      "  Episode 13 stopped at t=1500 \n",
      "  Episode 14 stopped at t=1500 \n",
      "  Episode 15 stopped at t=1500 \n",
      "  Episode 16 stopped at t=1500 \n",
      "  Episode 17 stopped at t=1500 \n",
      "  Episode 18 stopped at t=1500 \n",
      "  Episode 19 stopped at t=1500 \n",
      "  Episode 20 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "dql_run_5_toytest = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=gym_env,\n",
    "    environment_properties=ep,\n",
    "    learner=toy_my_dql_run_round_5['learner'],\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"DQL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96711c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toy_my_dql_run_round_10.pkl','rb') as file:\n",
    "    toy_my_dql_run_round_10 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "844ae0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Round_10_DQL\n",
      "Learning with: episode_count=20,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "  Episode 11 stopped at t=1500 \n",
      "  Episode 12 stopped at t=1500 \n",
      "  Episode 13 stopped at t=1500 \n",
      "  Episode 14 stopped at t=1500 \n",
      "  Episode 15 stopped at t=1500 \n",
      "  Episode 16 stopped at t=1500 \n",
      "  Episode 17 stopped at t=1500 \n",
      "  Episode 18 stopped at t=1500 \n",
      "  Episode 19 stopped at t=1500 \n",
      "  Episode 20 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "dql_run_10_toytest = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=gym_env,\n",
    "    environment_properties=ep,\n",
    "    learner=toy_my_dql_run_round_10['learner'],\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"Round_10_DQL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-hygiene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:35.261949Z",
     "iopub.status.busy": "2021-09-06T20:24:35.261332Z",
     "iopub.status.idle": "2021-09-06T20:24:59.634377Z",
     "shell.execute_reply": "2021-09-06T20:24:59.634882Z"
    },
    "papermill": {
     "duration": 24.387342,
     "end_time": "2021-09-06T20:24:59.635041",
     "exception": false,
     "start_time": "2021-09-06T20:24:35.247699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate a random agent that opportunistically exploits\n",
    "# credentials gathere in its local cache\n",
    "credlookup_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=rca.CredentialCacheExploiter(),\n",
    "    episode_count=10,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    render=False,\n",
    "    epsilon_exponential_decay=10000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"Credential lookups (ϵ-greedy)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-complex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:24:59.973053Z",
     "iopub.status.busy": "2021-09-06T20:24:59.972463Z",
     "iopub.status.idle": "2021-09-06T20:26:08.378512Z",
     "shell.execute_reply": "2021-09-06T20:26:08.379019Z"
    },
    "papermill": {
     "duration": 68.576074,
     "end_time": "2021-09-06T20:26:08.379612",
     "exception": false,
     "start_time": "2021-09-06T20:24:59.803538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate a Tabular Q-learning agent\n",
    "tabularq_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=tqa.QTabularLearner(\n",
    "        ep,\n",
    "        gamma=0.015, learning_rate=0.01, exploit_percentile=100),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.01,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"Tabular Q-learning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-enzyme",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:26:09.356292Z",
     "iopub.status.busy": "2021-09-06T20:26:09.355684Z",
     "iopub.status.idle": "2021-09-06T20:26:41.107282Z",
     "shell.execute_reply": "2021-09-06T20:26:41.107779Z"
    },
    "papermill": {
     "duration": 32.248104,
     "end_time": "2021-09-06T20:26:41.107982",
     "exception": false,
     "start_time": "2021-09-06T20:26:08.859878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate an agent that exploits the Q-table learnt above\n",
    "tabularq_exploit_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=tqa.QTabularLearner(\n",
    "        ep,\n",
    "        trained=tabularq_run['learner'],\n",
    "        gamma=0.0,\n",
    "        learning_rate=0.0,\n",
    "        exploit_percentile=90),\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    render=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"Exploiting Q-matrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coupled-initial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:26:42.340291Z",
     "iopub.status.busy": "2021-09-06T20:26:42.339674Z",
     "iopub.status.idle": "2021-09-06T20:34:39.450938Z",
     "shell.execute_reply": "2021-09-06T20:34:39.449964Z"
    },
    "papermill": {
     "duration": 477.730496,
     "end_time": "2021-09-06T20:34:39.451070",
     "exception": false,
     "start_time": "2021-09-06T20:26:41.720574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalic/Desktop/AI_P/CyberBattleSim/cyberbattle/agents/baseline/agent_dql.py:382: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  state_batch = torch.tensor(states_to_consider).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Deep Q-learning agent\n",
    "dql_run_yuan = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=gym_env,\n",
    "    environment_properties=ep,\n",
    "    learner=dqla.DeepQLearnerPolicy(\n",
    "        ep=ep,\n",
    "        gamma=0.015,\n",
    "        replay_memory_size=10000,\n",
    "        target_update=10,\n",
    "        batch_size=512,\n",
    "        # torch default learning rate is 1e-2\n",
    "        # a large value helps converge in less episodes\n",
    "        learning_rate=0.01\n",
    "    ),\n",
    "    # episode_count=training_episode_count,\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"DQL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e42bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Toy_results/my_dql_test_run_40.pkl','rb') as file:\n",
    "    my_dql_test_run_40 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f12f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### NVGIL DQL with special epsilon 40\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an agent that exploits the Q-function learnt above\n",
    "toy_my_dql_run_after_40_with_special_epsilon = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=my_dql_test_run_40['learner'],\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"NVGIL DQL with special epsilon 40\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "studied-quick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:34:43.045341Z",
     "iopub.status.busy": "2021-09-06T20:34:43.044686Z",
     "iopub.status.idle": "2021-09-06T20:39:29.094941Z",
     "shell.execute_reply": "2021-09-06T20:39:29.095430Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 287.883752,
     "end_time": "2021-09-06T20:39:29.095598",
     "exception": false,
     "start_time": "2021-09-06T20:34:41.211846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### NVGIL DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.0,ϵ_min=0.0, γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalic/Desktop/AI_P/CyberBattleSim/cyberbattle/agents/baseline/agent_dql.py:382: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  state_batch = torch.tensor(states_to_consider).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an agent that exploits the Q-function learnt above\n",
    "toy_my_dql_run_after_40 = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=load_m8['learner'],\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    epsilon_minimum=0.00,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"NVGIL DQL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36dd855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### NVGIL DQL with epsilon 40\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an agent that exploits the Q-function learnt above\n",
    "toy_my_dql_run_after_40_with_epsilon = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=load_m8['learner'],\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"NVGIL DQL with epsilon 40\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30693275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### dql_run_after_yuan\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.0,ϵ_min=0.0, γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an agent that exploits the Q-function learnt above\n",
    "toy_my_dql_run_after_yuan = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=dql_run_yuan['learner'],\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    epsilon_minimum=0.00,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"dql_run_after_yuan\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "threaded-funds",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:39:34.305992Z",
     "iopub.status.busy": "2021-09-06T20:39:34.305379Z",
     "iopub.status.idle": "2021-09-06T20:40:04.050412Z",
     "shell.execute_reply": "2021-09-06T20:40:04.050896Z"
    },
    "papermill": {
     "duration": 32.385593,
     "end_time": "2021-09-06T20:40:04.051053",
     "exception": false,
     "start_time": "2021-09-06T20:39:31.665460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Random search\n",
      "Learning with: episode_count=20,iteration_count=1500,ϵ=1.0,ϵ_min=0.0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "  Episode 11 stopped at t=1500 \n",
      "  Episode 12 stopped at t=1500 \n",
      "  Episode 13 stopped at t=1500 \n",
      "  Episode 14 stopped at t=1500 \n",
      "  Episode 15 stopped at t=1500 \n",
      "  Episode 16 stopped at t=1500 \n",
      "  Episode 17 stopped at t=1500 \n",
      "  Episode 18 stopped at t=1500 \n",
      "  Episode 19 stopped at t=1500 \n",
      "  Episode 20 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the random agent\n",
    "random_run_yuan = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=learner.RandomPolicy(),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=1.0,  # purely random\n",
    "    render=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"Random search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "failing-antibody",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:40:09.479410Z",
     "iopub.status.busy": "2021-09-06T20:40:09.476919Z",
     "iopub.status.idle": "2021-09-06T20:40:09.836548Z",
     "shell.execute_reply": "2021-09-06T20:40:09.835888Z"
    },
    "papermill": {
     "duration": 3.107909,
     "end_time": "2021-09-06T20:40:09.836694",
     "exception": false,
     "start_time": "2021-09-06T20:40:06.728785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare and plot results for all the agents\n",
    "all_runs = [\n",
    "    # random_run,\n",
    "    # credlookup_run,\n",
    "    # tabularq_run,\n",
    "    # tabularq_exploit_run,\n",
    "    # dql_run,\n",
    "    random_run_yuan,\n",
    "    dql_run_yuan\n",
    "    # dql_exploit_run\n",
    "]\n",
    "\n",
    "# Plot averaged cumulative rewards for DQL vs Random vs DQL-Exploit\n",
    "themodel = dqla.CyberBattleStateActionModel(ep)\n",
    "p.plot_averaged_cummulative_rewards(\n",
    "    all_runs=all_runs,\n",
    "    title=f'Benchmark -- max_nodes={ep.maximum_node_count}, episodes={eval_episode_count},\\n'\n",
    "    f'State: {[f.name() for f in themodel.state_space.feature_selection]} '\n",
    "    f'({len(themodel.state_space.feature_selection)}\\n'\n",
    "    f\"Action: abstract_action ({themodel.action_space.flat_size()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fd3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Toy_results/toy_random_run.pkl','rb') as file:\n",
    "    load_m1 = pickle.load(file)\n",
    "with open('Toy_results/toy_tabularq_run.pkl','rb') as file:\n",
    "    load_m2 = pickle.load(file)\n",
    "with open('Toy_results/toy_tabularq_exploit_run.pkl','rb') as file:\n",
    "    load_m3 = pickle.load(file)\n",
    "with open('Toy_results/toy_dql_run.pkl','rb') as file:\n",
    "    load_m4 = pickle.load(file)\n",
    "with open('Toy_results/my_dql_test_run_10.pkl','rb') as file:\n",
    "    load_m5 = pickle.load(file)\n",
    "with open('Toy_results/my_dql_test_run_20.pkl','rb') as file:\n",
    "    load_m6 = pickle.load(file)\n",
    "with open('Toy_results/my_dql_test_run_30.pkl','rb') as file:\n",
    "    load_m7 = pickle.load(file)\n",
    "with open('Toy_results/my_dql_test_run_40.pkl','rb') as file:\n",
    "    load_m8 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca90f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_m5['title'] = 'NVGIL10'\n",
    "load_m6['title'] = 'NVGIL20'\n",
    "load_m7['title'] = 'NVGIL30'\n",
    "load_m8['title'] = 'NVGIL40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8c8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toy_random_run_yuan.pkl','rb') as file:\n",
    "    random_run_yuan = pickle.load(file)\n",
    "with open('toy_dql_run_yuan.pkl','rb') as file:\n",
    "    dql_run_yuan = pickle.load(file)\n",
    "with open('toy_my_dql_run_after_40.pkl','rb') as file:\n",
    "    toy_my_dql_run_after_40 = pickle.load(file)    \n",
    "with open('toy_my_dql_run_after_40.pkl','rb') as file:\n",
    "    toy_my_dql_run_after_40 = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7d9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_run_yuan['title'] = \"Random\"\n",
    "dql_run_yuan['title'] = 'DQL'\n",
    "toy_my_dql_run_after_40_with_special_epsilon['title'] ='DQL with NGVIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "committed-violin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:40:15.544686Z",
     "iopub.status.busy": "2021-09-06T20:40:15.544046Z",
     "iopub.status.idle": "2021-09-06T20:40:16.181653Z",
     "shell.execute_reply": "2021-09-06T20:40:16.181117Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 3.469208,
     "end_time": "2021-09-06T20:40:16.181783",
     "exception": false,
     "start_time": "2021-09-06T20:40:12.712575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contenders = [\n",
    "    # credlookup_run,\n",
    "    # tabularq_run,\n",
    "    # dql_run,\n",
    "    # dql_exploit_run\n",
    "    #load_m2,\n",
    "    # random_run_1,\n",
    "    #load_m3,\n",
    "    random_run_yuan,\n",
    "    dql_run_yuan,\n",
    "    # toy_my_dql_run_after_yuan,\n",
    "    # toy_my_dql_run_after_40,\n",
    "    toy_my_dql_run_after_40_with_special_epsilon\n",
    "\n",
    "\n",
    "    # load_m4,\n",
    "\n",
    "    # load_m8,\n",
    "]\n",
    "pptxy.plot_episodes_length(contenders)\n",
    "pptxy.plot_averaged_cummulative_rewards(\n",
    "    title=f'Agent Benchmark top contenders\\n'\n",
    "    f'max_nodes:{ep.maximum_node_count}\\n',\n",
    "    all_runs=contenders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wanted-hacker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:40:21.801670Z",
     "iopub.status.busy": "2021-09-06T20:40:21.800793Z",
     "iopub.status.idle": "2021-09-06T20:40:23.138026Z",
     "shell.execute_reply": "2021-09-06T20:40:23.138537Z"
    },
    "papermill": {
     "duration": 4.219713,
     "end_time": "2021-09-06T20:40:23.138695",
     "exception": false,
     "start_time": "2021-09-06T20:40:18.918982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot cumulative rewards for all episodes\n",
    "for r in contenders:\n",
    "    p.plot_all_episodes(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('test/toy_my_test/toy_random_run.pkl','rb') as file:\n",
    "    load1 = pickle.load(file)\n",
    "with open('test/toy_my_test/toy_tabularq_run.pkl','rb') as file:\n",
    "    load2 = pickle.load(file)\n",
    "with open('test/toy_my_test/dql_run_10_toytest_on_toyctf.pkl','rb') as file:\n",
    "    load3 = pickle.load(file)\n",
    "with open('test/toy_my_test/toy_dql_run.pkl','rb') as file:\n",
    "    load4 = pickle.load(file)\n",
    "with open('test/toy_my_test/toy_my_dql_run_round_10.pkl','rb') as file:\n",
    "    load5 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd0155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2df8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toy_paper_results/random_run_yuan.pkl','wb') as file:\n",
    "    pickle.dump(random_run_yuan, file)\n",
    "with open('toy_paper_results/dql_run_yuan.pkl','wb') as file:\n",
    "    pickle.dump(dql_run_yuan, file)\n",
    "with open('toy_paper_results/toy_my_dql_run_after_40_with_special_epsilon.pkl','wb') as file:\n",
    "    pickle.dump(toy_my_dql_run_after_40_with_special_epsilon, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd2bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyberbattle.agents.baseline.plotting as pptxy"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "virtualforcyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 959.742951,
   "end_time": "2021-09-06T20:40:32.440713",
   "environment_variables": {},
   "exception": null,
   "input_path": "-",
   "output_path": "output/notebook_benchmark-toyctf.ipynb",
   "parameters": {
    "eval_episode_count": 10,
    "gymid": "CyberBattleToyCtf-v0",
    "iteration_count": 1500,
    "maximum_node_count": 12,
    "maximum_total_credentials": 10,
    "training_episode_count": 20
   },
   "start_time": "2021-09-06T20:24:32.697762",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
