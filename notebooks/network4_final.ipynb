{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifiers(properties=['CTFFLAG:LeakedCustomerData', 'CTFFLAG:LeakedCustomerData2', 'CTFFLAG:Readme.txt-Discover secret data', 'CTFFLAG:VMPRIVATEINFO', 'GitHub', 'MySql', 'SasUrlInCommit', 'SharepointLeakingPassword', 'Ubuntu', 'nginx/1.10.3'], ports=['GIT', 'HTTPS', 'MySQL', 'PING', 'SSH', 'SSH-key', 'su'], local_vulnerabilities=['CredScan-HomeDirectory', 'CredScanBashHistory', 'SearchEdgeHistory'], remote_vulnerabilities=['AccessDataWithSASToken', 'CredScanGitHistory', 'ListAzureResources', 'NavigateWebDirectory', 'NavigateWebDirectoryFurther', 'ScanPageContent', 'ScanPageSource', 'ScanSharepointParentDirectory'])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kalic/Desktop/AI_P/CyberBattleSim\")\n",
    "import logging\n",
    "import gym\n",
    "import pickle\n",
    "import cyberbattle.agents.baseline.learner as learner\n",
    "import cyberbattle.agents.baseline.plotting as p\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "import cyberbattle.agents.baseline.agent_randomcredlookup as rca\n",
    "import cyberbattle.agents.baseline.agent_tabularqlearning as tqa\n",
    "import cyberbattle.agents.baseline.agent_dql as dqla\n",
    "from cyberbattle.agents.baseline.agent_wrapper import Verbosity\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# Papermill notebook parameters\n",
    "\n",
    "#############\n",
    "# gymid = 'CyberBattleTiny-v0'\n",
    "#############\n",
    "gymid = \"network4-v0\"\n",
    "env_size = None\n",
    "iteration_count = 1500\n",
    "training_episode_count = 1\n",
    "eval_episode_count = 10\n",
    "maximum_node_count = 12\n",
    "maximum_total_credentials = 10\n",
    "\n",
    "# Load the Gym environment\n",
    "if env_size:\n",
    "    gym_env = gym.make(gymid)\n",
    "else:\n",
    "    gym_env = gym.make(gymid)\n",
    "\n",
    "ep = w.EnvironmentBounds.of_identifiers(\n",
    "    maximum_node_count=maximum_node_count,\n",
    "    maximum_total_credentials=maximum_total_credentials,\n",
    "    identifiers=gym_env.identifiers\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "state = \"not_random\"\n",
    "os_type = [\"Windows\", \"Ubuntu\", \"Windows\", \"Ubuntu\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\"]\n",
    "Local_vulnerabilities = [[], [\"CVE-2017-16995\"], [\"CVE-2009-0079\"], [\"CVE-2017-16995\"], [\"MS15-015\"], [], [], [], [], []]\n",
    "Remote_vulnerabilities = [[], [\"CVE-2019-2729\"], [\"S2-048\"], [], [\"CNVD-2019-32204\"], [\"MS17-010\"], [\"MS17-010\"], [\"MS08-067\"], [\"CVE-2019-0708\"],[\"MS09-050\"]]\n",
    "node_values = [0, 50, 30, 60, 60, 50, 50, 50, 300, 1000]\n",
    "topology_graph = {\"0\":[\"1\",\"2\"], \"1\":[\"3\"],\"3\":[\"4\",\"5\",\"6\",\"7\",\"8\"], \"4\":[\"5\",\"6\",\"7\",\"8\"], \"5\":[\"6\",\"7\",\"8\"], \"6\":[\"7\", \"8\"], \"7\":[\"8\"], \"8\":[\"9\"]}\n",
    "network1 = gym.make(gymid, state = state, os_type = os_type, Local_vulnerabilities = Local_vulnerabilities, Remote_vulnerabilities = Remote_vulnerabilities, node_values = node_values, topology_graph = topology_graph)\n",
    "\n",
    "\n",
    "state = \"not_random\"\n",
    "os_type = [\"Ubuntu\", \"Ubuntu\", \"Windows\", \"Ubuntu\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Ubuntu\"]\n",
    "Local_vulnerabilities = [[], [\"CVE-2017-16995\"], [\"CVE-2009-0079\"], [\"CVE-2017-16995\"], [\"MS15-015\"], [\"MS16-111\"], [\"CVE-2009-0079\"], [], [], [\"CVE-2022-0847\"]]\n",
    "Remote_vulnerabilities = [[], [\"CVE-2019-2729\"], [\"S2-048\"], [], [\"CNVD-2019-32204\"], [\"MS17-010\"], [\"MS17-010\"], [\"MS08-067\"], [\"CVE-2019-0708\"],[\"S2-048\"]]\n",
    "node_values = [0, 30, 50, 60, 60, 100, 20, 300, 50, 1000]\n",
    "topology_graph = {\"0\":[\"1\", \"2\"],\"1\":[\"3\"],\"3\":[\"5\"] , \"5\":[\"7\",\"8\"],\"7\":[\"9\"],\"2\":[\"4\"], \"4\":[\"6\"], \"6\":[\"8\"]}\n",
    "network2 = gym.make(gymid, state = state, os_type = os_type, Local_vulnerabilities = Local_vulnerabilities, Remote_vulnerabilities = Remote_vulnerabilities, node_values = node_values, topology_graph = topology_graph)\n",
    "\n",
    "\n",
    "os_type = [\"Windows\", \"Ubuntu\", \"Windows\", \"Ubuntu\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\"]\n",
    "Local_vulnerabilities = [[\"Search\"], [\"CVE-2017-16995\"], [\"CVE-2009-0079\"], [\"CVE-2017-16995\"], [\"MS15-015\"], [\"MS16-111\"], [\"CVE-2009-0079\"], [], [\"CVE-2009-0079\"], []]\n",
    "Remote_vulnerabilities = [[], [\"CVE-2019-2729\"], [\"S2-048\"], [], [\"CNVD-2019-32204\"], [\"MS17-010\"], [\"MS17-010\"], [\"MS08-067\"], [\"CVE-2019-0708\"],[\"MS09-050\"]]\n",
    "node_values = [0, 70, 50, 100, 60, 200, 50, 100, 500, 100]\n",
    "topology_graph = {\"0\":[\"3\"], \"3\":[\"1\", \"2\", \"6\"], \"2\":[\"9\"], \"1\":[\"4\"], \"5\":[\"7\", \"8\"], \"6\":[\"8\"]}\n",
    "network3 = gym.make(gymid, state = state, os_type = os_type, Local_vulnerabilities = Local_vulnerabilities, Remote_vulnerabilities = Remote_vulnerabilities, node_values = node_values, topology_graph = topology_graph)\n",
    "# topology_graph = {(0,3),(3,1),(3,2),(3,6),(2,9),(1,4),(4,7),(5,7),(5,8),(6,8)}\n",
    "\n",
    "\n",
    "os_type = [\"Windows\", \"Ubuntu\", \"Windows\", \"Ubuntu\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\", \"Windows\"]\n",
    "Local_vulnerabilities = [[\"Search\"], [], [\"CVE-2009-0079\"], [\"CVE-2017-16995\"], [\"MS15-015\"], [\"MS16-111\"], [\"CVE-2009-0079\"], [], [\"CVE-2019-0708\"], []]\n",
    "Remote_vulnerabilities = [[], [\"CVE-2019-2729\"], [\"S2-048\"], [], [\"CNVD-2019-32204\"], [], [\"MS17-010\"], [\"MS08-067\"], [\"MS16-111\",\"CVE-2019-0708\"],[]]\n",
    "node_values = [0, 30,50,60,60,100,100,200,200,600]\n",
    "topology_graph = {\"0\":[\"3\"], \"3\":[\"1\"], \"4\":[\"2\", \"6\"], \"2\":[\"5\"], \"6\":[\"8\"], \"5\":[\"7\"], \"8\":[\"7\",\"9\"]}\n",
    "network4 = gym.make(gymid, state = state, os_type = os_type, Local_vulnerabilities = Local_vulnerabilities, Remote_vulnerabilities = Remote_vulnerabilities, node_values = node_values, topology_graph = topology_graph)\n",
    "# topology_graph = {(0,3),(3,1),(4,2),(4,6),(2,5),(6,8),(5,7),(8,7),(8,9)}\n",
    "\n",
    "Network_List = [network1, network2, network3, network4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "jjjjjjjjjjjjjjj= 0\n",
      "###### Random search\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=1.0,ϵ_min=0.0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "###### DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalic/Desktop/AI_P/CyberBattleSim/cyberbattle/agents/baseline/agent_dql.py:382: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  state_batch = torch.tensor(states_to_consider).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "*********************************************************************\n",
      "jjjjjjjjjjjjjjj= 1\n",
      "###### Random search\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=1.0,ϵ_min=0.0, \n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "###### DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "*********************************************************************\n",
      "jjjjjjjjjjjjjjj= 2\n",
      "###### Random search\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=1.0,ϵ_min=0.0, \n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "###### DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "*********************************************************************\n",
      "jjjjjjjjjjjjjjj= 3\n",
      "###### Random search\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=1.0,ϵ_min=0.0, \n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n",
      "###### DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "for j in range(4):\n",
    "    print(\"*********************************************************************\")\n",
    "    print(\"jjjjjjjjjjjjjjj=\", j)\n",
    "    random_run = learner.epsilon_greedy_search(\n",
    "        Network_List[j],\n",
    "        ep,\n",
    "        learner=learner.RandomPolicy(),\n",
    "        episode_count=eval_episode_count,\n",
    "        iteration_count=iteration_count,\n",
    "        epsilon=1.0,  # purely random\n",
    "        render=False,\n",
    "        verbosity=Verbosity.Quiet,\n",
    "        plot_episodes_length=False,\n",
    "        title=\"Random search\"\n",
    "    )\n",
    "    filenamei = './Network4_results/random_run' + 'network' + str(j+1) + '.pkl'\n",
    "    with open(filenamei,'wb') as file:\n",
    "        pickle.dump(random_run, file)\n",
    "\n",
    "    # Evaluate a random agent that opportunistically exploits\n",
    "    # credentials gathere in its local cache\n",
    "    # credlookup_run = learner.epsilon_greedy_search(\n",
    "    #     Network_List[j],\n",
    "    #     ep,\n",
    "    #     learner=rca.CredentialCacheExploiter(),\n",
    "    #     episode_count=training_episode_count,\n",
    "    #     iteration_count=iteration_count,\n",
    "    #     epsilon=0.90,\n",
    "    #     render=False,\n",
    "    #     epsilon_exponential_decay=10000,\n",
    "    #     epsilon_minimum=0.10,\n",
    "    #     verbosity=Verbosity.Quiet,\n",
    "    #     title=\"Credential lookups (ϵ-greedy)\"\n",
    "    # )\n",
    "    # filenamei = './Network4_results/credlookup_run' + 'network' + str(j+1) + '.pkl'\n",
    "    # with open(filenamei,'wb') as file:\n",
    "    #     pickle.dump(credlookup_run, file)\n",
    "\n",
    "    # # Evaluate a Tabular Q-learning agent\n",
    "    # tabularq_run = learner.epsilon_greedy_search(\n",
    "    #     Network_List[j],\n",
    "    #     ep,\n",
    "    #     learner=tqa.QTabularLearner(\n",
    "    #         ep,\n",
    "    #         gamma=0.015, learning_rate=0.01, exploit_percentile=100),\n",
    "    #     episode_count=training_episode_count,\n",
    "    #     iteration_count=iteration_count,\n",
    "    #     epsilon=0.90,\n",
    "    #     epsilon_exponential_decay=5000,\n",
    "    #     epsilon_minimum=0.01,\n",
    "    #     verbosity=Verbosity.Quiet,\n",
    "    #     render=False,\n",
    "    #     plot_episodes_length=False,\n",
    "    #     title=\"Tabular Q-learning\"\n",
    "    # )\n",
    "    # filenamei = './Network4_results/tabularq_run' + 'network' + str(j+1) + '.pkl'\n",
    "    # with open(filenamei,'wb') as file:\n",
    "    #     pickle.dump(tabularq_run, file)\n",
    "\n",
    "\n",
    "    # Evaluate an agent that exploits the Q-table learnt above\n",
    "    # tabularq_exploit_run = learner.epsilon_greedy_search(\n",
    "    #     Network_List[j],\n",
    "    #     ep,\n",
    "    #     learner=tqa.QTabularLearner(\n",
    "    #         ep,\n",
    "    #         trained=tabularq_run['learner'],\n",
    "    #         gamma=0.0,\n",
    "    #         learning_rate=0.0,\n",
    "    #         exploit_percentile=90),\n",
    "    #     episode_count=eval_episode_count,\n",
    "    #     iteration_count=iteration_count,\n",
    "    #     epsilon=0.0,\n",
    "    #     render=False,\n",
    "    #     verbosity=Verbosity.Quiet,\n",
    "    #     title=\"Exploiting Q-matrix\"\n",
    "    # )\n",
    "    # filenamei = './Network4_results/tabularq_exploit_run' + 'network' + str(j+1) + '.pkl'\n",
    "    # with open(filenamei,'wb') as file:\n",
    "    #     pickle.dump(tabularq_exploit_run, file)\n",
    "\n",
    "    # Evaluate the Deep Q-learning agent\n",
    "    dql_run = learner.epsilon_greedy_search(\n",
    "        cyberbattle_gym_env=Network_List[j],\n",
    "        environment_properties=ep,\n",
    "        learner=dqla.DeepQLearnerPolicy(\n",
    "            ep=ep,\n",
    "            gamma=0.015,\n",
    "            replay_memory_size=10000,\n",
    "            target_update=10,\n",
    "            batch_size=512,\n",
    "            # torch default learning rate is 1e-2\n",
    "            # a large value helps converge in less episodes\n",
    "            learning_rate=0.01\n",
    "        ),\n",
    "        episode_count=training_episode_count,\n",
    "        iteration_count=iteration_count,\n",
    "        epsilon=0.90,\n",
    "        epsilon_exponential_decay=5000,\n",
    "        epsilon_minimum=0.10,\n",
    "        verbosity=Verbosity.Quiet,\n",
    "        render=False,\n",
    "        plot_episodes_length=False,\n",
    "        title=\"DQL\"\n",
    "    )\n",
    "    filenamei = './Network4_results/dql_run' + 'network' + str(j+1) + '.pkl'\n",
    "    with open(filenamei,'wb') as file:\n",
    "        pickle.dump(dql_run, file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### DQL\n",
      "Learning with: episode_count=1,iteration_count=1500,ϵ=0.9,ϵ_min=0.1, ϵ_expdecay=5000,γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "dql_run_1 = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=Network_List[1],\n",
    "    environment_properties=ep,\n",
    "    learner=dqla.DeepQLearnerPolicy(\n",
    "        ep=ep,\n",
    "        gamma=0.015,\n",
    "        replay_memory_size=10000,\n",
    "        target_update=10,\n",
    "        batch_size=512,\n",
    "        # torch default learning rate is 1e-2\n",
    "        # a large value helps converge in less episodes\n",
    "        learning_rate=0.01\n",
    "    ),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    # episode_count=eval_episode_count,\n",
    "    # iteration_count=iteration_count,\n",
    "    # epsilon=0.0,\n",
    "    # epsilon_minimum=0.00,\n",
    "    # render=False,\n",
    "    # plot_episodes_length=False,\n",
    "    # verbosity=Verbosity.Quiet,\n",
    "    title=\"DQL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### DQL-Random\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.0,ϵ_min=0.0, γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalic/Desktop/AI_P/CyberBattleSim/cyberbattle/agents/baseline/agent_dql.py:382: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  state_batch = torch.tensor(states_to_consider).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "dql_run = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=Network_List[0],\n",
    "    environment_properties=ep,\n",
    "    learner=dqla.DeepQLearnerPolicy(\n",
    "        ep=ep,\n",
    "        gamma=0.015,\n",
    "        replay_memory_size=10000,\n",
    "        target_update=10,\n",
    "        batch_size=512,\n",
    "        # torch default learning rate is 1e-2\n",
    "        # a large value helps converge in less episodes\n",
    "        learning_rate=0.01\n",
    "    ),\n",
    "    # episode_count=training_episode_count,\n",
    "    # iteration_count=iteration_count,\n",
    "    # epsilon=0.90,\n",
    "    # epsilon_exponential_decay=5000,\n",
    "    # epsilon_minimum=0.10,\n",
    "    # verbosity=Verbosity.Quiet,\n",
    "    # render=False,\n",
    "    # plot_episodes_length=False,\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    epsilon_minimum=0.00,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"DQL-Random\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### NVGIL-DQL\n",
      "Learning with: episode_count=10,iteration_count=1500,ϵ=0.0,ϵ_min=0.0, γ=0.015, lr=0.01, replaymemory=10000,\n",
      "batch=512, target_update=10\n",
      "  Episode 1 stopped at t=1500 \n",
      "  Episode 2 stopped at t=1500 \n",
      "  Episode 3 stopped at t=1500 \n",
      "  Episode 4 stopped at t=1500 \n",
      "  Episode 5 stopped at t=1500 \n",
      "  Episode 6 stopped at t=1500 \n",
      "  Episode 7 stopped at t=1500 \n",
      "  Episode 8 stopped at t=1500 \n",
      "  Episode 9 stopped at t=1500 \n",
      "  Episode 10 stopped at t=1500 \n",
      "simulation ended\n"
     ]
    }
   ],
   "source": [
    "# for j in range(4):\n",
    "filenamei = './Network4_results/my_dql_test_run3000' + '30' + '.pkl'\n",
    "with open(filenamei, 'rb') as file:\n",
    "    trained_networki = pickle.load(file)\n",
    "my_dql_run = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=Network_List[3],\n",
    "    environment_properties=ep,\n",
    "    learner=trained_networki['learner'],\n",
    "    # episode_count=training_episode_count,\n",
    "    # iteration_count=iteration_count,\n",
    "    # epsilon=0.90,\n",
    "    # epsilon_exponential_decay=5000,\n",
    "    # epsilon_minimum=0.10,\n",
    "    # verbosity=Verbosity.Quiet,\n",
    "    # render=False,\n",
    "    # plot_episodes_length=False,\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    epsilon_minimum=0.00,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"NVGIL-DQL\"\n",
    ") \n",
    "filenamei = './Network4_results/my_dql_test_run3000_' + 'network' + str(3) + 'result.pkl'\n",
    "with open(filenamei,'wb') as file:\n",
    "    pickle.dump(my_dql_run, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gym_env_for_train = gym.make(gymid, state = 'not_random', os_type = [], Local_vulnerabilities = [], Remote_vulnerabilities = [], node_values = [], topology_graph = set())\n",
    "# Evaluate the Deep Q-learning agent\n",
    "my_dql_run = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=gym_env,\n",
    "    environment_properties=ep,\n",
    "    learner=dqla.DeepQLearnerPolicy(\n",
    "        ep=ep,\n",
    "        gamma=0.015,\n",
    "        replay_memory_size=10000,\n",
    "        target_update=10,\n",
    "        batch_size=512,\n",
    "        # torch default learning rate is 1e-2\n",
    "        # a large value helps converge in less episodes\n",
    "        learning_rate=0.01\n",
    "    ),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"NVGIL-DQL\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./Network4_results/random_runnetwork4.pkl','rb') as file:\n",
    "#     random_run = pickle.load(file)\n",
    "with open('./Network4_results/yuan_dql_test_run1500_network1.pkl','rb') as file:\n",
    "    dql_run = pickle.load(file)\n",
    "# with open('./Network4_results/0my_dql_test_run1500_network1.pkl','rb') as file:\n",
    "#     my_dql_run = pickle.load(file)\n",
    "with open('./Network4_results/random_runnetwork1.pkl','rb') as file:\n",
    "    random_runnetwork1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/yuan_dql_test_run1500_network2.pkl','rb') as file:\n",
    "    dql_run2 = pickle.load(file)\n",
    "\n",
    "with open('./Network4_results/random_runnetwork2.pkl','rb') as file:\n",
    "    random_runnetwork2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/yuan_dql_test_run1500_network3.pkl','rb') as file:\n",
    "    dql_run3 = pickle.load(file)\n",
    "with open('./Network4_results/random_runnetwork3.pkl','rb') as file:\n",
    "    random_runnetwork3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/yuan_dql_test_run1500_network4.pkl','rb') as file:\n",
    "    dql_run4 = pickle.load(file)\n",
    "with open('./Network4_results/random_runnetwork4.pkl','rb') as file:\n",
    "    random_runnetwork4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./Network4_results/exploit_yuan_dql_test_run1500_network1.pkl','rb') as file:\n",
    "    exp_dql_run1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./Network4_results/my_dql_test_run1500_20network1.pkl','rb') as file:\n",
    "    my_dql_run = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./Network4_results/0109_my_dql_test_run1500_network1.pkl','rb') as file:\n",
    "    my_dql_run_0109 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/0109_my_dql_test_run1500_network2.pkl','rb') as file:\n",
    "    my_dql_run_0109_2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/0109_my_dql_test_run1500_network3.pkl','rb') as file:\n",
    "    my_dql_run_0109_3= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network4_results/0109_my_dql_test_run1500_network4.pkl','rb') as file:\n",
    "    my_dql_run_0109_4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_run['title'] = \"Random\"\n",
    "dql_run4['title'] = 'DQL'\n",
    "random_runnetwork4['title'] = 'Random'\n",
    "my_dql_run_0109_4['title'] ='NGVIL-DQL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contenders = [\n",
    "    random_runnetwork4,\n",
    "    # exp_dql_run1,\n",
    "    # dql_run,\n",
    "    # dql_run2,\n",
    "    # my_dql_run\n",
    "    # dql_run3,\n",
    "    dql_run4,\n",
    "\n",
    "\n",
    "    # my_dql_run_0109\n",
    "    # my_dql_run_0109_2,\n",
    "    # my_dql_run_0109_3,\n",
    "    my_dql_run_0109_4\n",
    "    # my_dql_run\n",
    "    # credlookup_run,\n",
    "    # tabularq_run,\n",
    "    # tabularq_exploit_run,\n",
    "    # dql_run,\n",
    "    # my_dql_run\n",
    "    # dql_exploit_run\n",
    "]\n",
    "\n",
    "# Plot averaged cumulative rewards for DQL vs Random vs DQL-Exploit\n",
    "p.plot_episodes_length(contenders)\n",
    "p.plot_averaged_cummulative_rewards(\n",
    "    title=f'Agent Benchmark top contenders\\n'\n",
    "    f'max_nodes:{ep.maximum_node_count}\\n',\n",
    "    all_runs=contenders)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualforcyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
